{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ca28e7-0fe9-4553-add0-9215602fca5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T12:22:39.198213Z",
     "iopub.status.busy": "2025-06-26T12:22:39.198073Z",
     "iopub.status.idle": "2025-06-26T12:22:40.369143Z",
     "shell.execute_reply": "2025-06-26T12:22:40.368640Z",
     "shell.execute_reply.started": "2025-06-26T12:22:39.198197Z"
    },
    "tags": []
   },
   "source": [
    "# New Extraction Spectral data from Butler\n",
    "\n",
    "- from Tuto of Corentin R on Spectractor, May 28th 2025\n",
    "- After adapting path of Butler in atmospec/spectraction.py\n",
    "- adaptation : Sylvie Dagoret-Campagne\n",
    "- creation date : 2025-12-11\n",
    "\n",
    "- last update : 2025-10-21 : process run_v9\n",
    "- last update : 2025-10-21 : process run_v10\n",
    "- last update : 2025-10-25 : process run_v11\n",
    "- last update : 2025-12-11 : process run_v12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fd38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "EXTR_viewSpectractorResults_December2025_repomain-new.py\n",
    "\n",
    "Standalone script extracted from the Jupyter notebook:\n",
    "EXTR_viewSpectractorResults_December2025_repomain-new.ipynb\n",
    "\n",
    "Purpose:\n",
    "- Query a Butler repo for 'spectractorSpectrum' datasets,\n",
    "- extract Libradtran fit parameters (spectrum & spectrogram),\n",
    "- assemble a DataFrame and save a Numpy record array (np.save) as in the original notebook.\n",
    "- Optionally produce non-interactive plots (saved as PNG).\n",
    "- Default: do not display figures.\n",
    "\n",
    "Notes:\n",
    "- If available, imports BUTLER00_parameters for repo/collection defaults; otherwise they can be provided via CLI.\n",
    "- Requires conda_py313 environment and Rubin dependencies (Butler, rubinsimphot as needed).\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# If you have local libs in /notebooks/.../lib, add them robustly\n",
    "import os as _os\n",
    "_script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "_lib_dir = os.path.join(_script_dir, \"..\", \"lib\")\n",
    "_lib_dir = os.path.normpath(_lib_dir)\n",
    "if os.path.exists(_lib_dir) and _lib_dir not in sys.path:\n",
    "    sys.path.append(_lib_dir)\n",
    "\n",
    "# try importing Butler parameters local module\n",
    "try:\n",
    "    from BUTLER00_parameters import *\n",
    "except Exception:\n",
    "    # If that module is not available, we'll fallback to CLI-provided args\n",
    "    pass\n",
    "\n",
    "# import Butler related only when we need it (to reduce import errors when CLI checks)\n",
    "try:\n",
    "    import lsst.daf.butler as dafButler\n",
    "except Exception:\n",
    "    dafButler = None\n",
    "\n",
    "# matplotlib settings for headless operation (no GUI)\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional extra module used in the notebook:\n",
    "try:\n",
    "    import getCalspec\n",
    "except Exception:\n",
    "    getCalspec = None\n",
    "\n",
    "\n",
    "def configure_logging(verbose: bool = False) -> None:\n",
    "    \"\"\"Set logging to INFO or DEBUG depending on the verbose flag.\"\"\"\n",
    "    level = logging.DEBUG if verbose else logging.INFO\n",
    "    logging.basicConfig(level=level, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    \"\"\"Parse command line arguments for script operation.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Extract spectractor/Libradtran parameters from a Butler repo.\")\n",
    "    parser.add_argument(\"--repo\", default=None, help=\"Butler repo path (defaults to repo from parameters or /repo/main).\")\n",
    "    parser.add_argument(\"--embargo\", action=\"store_true\", help=\"Use embargo repo (/repo/embargo).\")\n",
    "    parser.add_argument(\"--version-run\", default=None, help=\"Version run key for butlerusercollectiondict (defaults from parameters when available).\")\n",
    "    parser.add_argument(\"--collection\", default=None, help=\"Explicit collection name to use.\")\n",
    "    parser.add_argument(\"--out-file\", default=None, help=\"Output filename (np.save) to hold the final record array.\")\n",
    "    parser.add_argument(\"--n-workers\", type=int, default=16, help=\"Number of worker processes for pool.\")\n",
    "    parser.add_argument(\"--filter-instrument\", default=\"LATISS\", help=\"Instrument filter name for the dataset query.\")\n",
    "    parser.add_argument(\"--dry-run\", action=\"store_true\", help=\"If set, do not write output file.\")\n",
    "    parser.add_argument(\"--plot\", action=\"store_true\", help=\"If set, save summary plots to a results directory.\")\n",
    "    parser.add_argument(\"--plot-dir\", default=\"plots\", help=\"Directory to save plots if --plot is set.\")\n",
    "    parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Verbose logging.\")\n",
    "    parser.add_argument(\"--only-check\", action=\"store_true\", help=\"Only check presence of datasets and print counts then exit.\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def initialize_butler(repo: str | None, embargo: bool):\n",
    "    \"\"\"Initialize a Butler from the repo path (or default).\"\"\"\n",
    "    if repo is None:\n",
    "        if 'FLAG_REPO_EMBARGO' in globals() and FLAG_REPO_EMBARGO:\n",
    "            repo = \"/repo/embargo\"\n",
    "        else:\n",
    "            repo = \"/repo/main\"\n",
    "    if embargo:\n",
    "        repo = \"/repo/embargo\"\n",
    "\n",
    "    if dafButler is None:\n",
    "        raise RuntimeError(\"lsst.daf.butler is not importable. Activate the right environment (conda_py313).\")\n",
    "\n",
    "    logging.info(\"Initializing Butler with repo: %s\", repo)\n",
    "    butler = dafButler.Butler(repo)\n",
    "    return butler\n",
    "\n",
    "\n",
    "def get_collection_from_parameters(version_run_arg: str | None, collection_arg: str | None):\n",
    "    \"\"\"Get collection name from passed args or from the imported parameters if available.\"\"\"\n",
    "    if collection_arg:\n",
    "        logging.info(\"Using explicit collection: %s\", collection_arg)\n",
    "        return collection_arg\n",
    "\n",
    "    if version_run_arg is None and 'version_run' in globals():\n",
    "        version_run_arg = version_run\n",
    "\n",
    "    if version_run_arg and 'butlerusercollectiondict' in globals() and version_run_arg in butlerusercollectiondict:\n",
    "        return butlerusercollectiondict[version_run_arg]\n",
    "\n",
    "    if 'collection_validation' in globals():\n",
    "        return collection_validation\n",
    "\n",
    "    raise RuntimeError(\"Collection not found. Provide --collection or ensure BUTLER00_parameters defines it.\")\n",
    "\n",
    "\n",
    "def query_dataset_and_records(butler, my_collection, instrument='LATISS'):\n",
    "    \"\"\"\n",
    "    Query datasets and records:\n",
    "    - datasetRefs: dataset references for 'spectractorSpectrum'\n",
    "    - records: dimension records for 'visit' with that dataset\n",
    "    - refs: unique dataset refs\n",
    "    \"\"\"\n",
    "    registry = butler.registry\n",
    "    where = f\"instrument='{instrument}'\"\n",
    "    datasetRefs = registry.queryDatasets(datasetType='spectractorSpectrum', collections=[my_collection], where=where)\n",
    "    records = list(registry.queryDimensionRecords('visit', datasets='spectractorSpectrum', where=where,  collections=[my_collection]))\n",
    "    refs = list(set(registry.queryDatasets('spectractorSpectrum',  where=where,  collections=[my_collection])))\n",
    "    logging.info(\"Number of records: %d\", len(records))\n",
    "    logging.info(\"Number of datasetRefs: %d\", len(datasetRefs))\n",
    "    return datasetRefs, records, refs\n",
    "\n",
    "\n",
    "def extract_results(ref, my_collection, butler):\n",
    "    \"\"\"\n",
    "    Given a dataset ref, fetch:\n",
    "    - spectractorSpectrum\n",
    "    - spectrumLibradtranFitParameters\n",
    "    - spectrogramLibradtranFitParameters\n",
    "    Return header, spectrumParams, spectrogramParams\n",
    "    \"\"\"\n",
    "    try:\n",
    "        spec = butler.get(\n",
    "            \"spectractorSpectrum\",\n",
    "            visit=ref.dataId[\"visit\"],\n",
    "            collections=[my_collection],\n",
    "            detector=0,\n",
    "            instrument=\"LATISS\",\n",
    "        )\n",
    "        header = spec.header.copy()\n",
    "        header[\"ID\"] = ref.dataId[\"visit\"]\n",
    "\n",
    "        params_spectrum = butler.get(\n",
    "            \"spectrumLibradtranFitParameters\",\n",
    "            visit=ref.dataId[\"visit\"],\n",
    "            collections=[my_collection],\n",
    "            detector=0,\n",
    "            instrument=\"LATISS\",\n",
    "        )\n",
    "        params_spectrogram = butler.get(\n",
    "            \"spectrogramLibradtranFitParameters\",\n",
    "            visit=ref.dataId[\"visit\"],\n",
    "            collections=[my_collection],\n",
    "            detector=0,\n",
    "            instrument=\"LATISS\",\n",
    "        )\n",
    "        return header, params_spectrum, params_spectrogram\n",
    "    except Exception as e:\n",
    "        # Return None to mark missing dataset/exception\n",
    "        logging.debug(\"Exception while extracting %s: %s\", ref, str(e))\n",
    "        return None\n",
    "\n",
    "\n",
    "def pool_extract(refs, butler, my_collection, n_workers=16):\n",
    "    \"\"\"\n",
    "    Extract result via a multiprocess Pool or sequentially if n_workers=1.\n",
    "    Returns a list of results (header, spectrum params, spectrogram params) or None entries.\n",
    "    \"\"\"\n",
    "    extract_func = partial(extract_results, my_collection=my_collection, butler=butler)\n",
    "    if n_workers > 1:\n",
    "        with mp.Pool(n_workers) as pool:\n",
    "            results = list(pool.imap(extract_func, refs))\n",
    "    else:\n",
    "        results = [extract_func(r) for r in refs]\n",
    "    return results\n",
    "\n",
    "\n",
    "def concatenate_results_and_save(results, records, file_save, dry_run=False):\n",
    "    \"\"\"\n",
    "    From results (list of tuples or None) and records, create the Pandas DataFrame and save rec as np.save\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    params_spectrum = []\n",
    "    params_spectrogram = []\n",
    "\n",
    "    nskip = 0\n",
    "    for res in results:\n",
    "        if res is None:\n",
    "            nskip += 1\n",
    "        else:\n",
    "            headers.append(res[0])\n",
    "            params_spectrum.append(res[1])\n",
    "            params_spectrogram.append(res[2])\n",
    "    logging.info(\"Skipping %d failed results\", nskip)\n",
    "\n",
    "    if not headers:\n",
    "        raise RuntimeError(\"No valid headers extracted; aboring.\")\n",
    "\n",
    "    # Build column lists\n",
    "    columns_spectrum = [\"id\"]\n",
    "    for h in headers[0]:\n",
    "        if \"COMMENT\" in h or \"EXTNAME\" in h:\n",
    "            continue\n",
    "        if \"LBDAS_T\" in h or \"PSF_P_T\" in h or \"AMPLIS_T\" in h:\n",
    "            continue\n",
    "        if \"UNIT\" in h:\n",
    "            continue\n",
    "        if \"SIMPLE\" in h:\n",
    "            continue\n",
    "        columns_spectrum.append(h)\n",
    "\n",
    "    columns_spectrogram_bestfit = []\n",
    "    for key in params_spectrogram[0].labels:\n",
    "        columns_spectrogram_bestfit.append(key)\n",
    "        columns_spectrogram_bestfit.append(key + \"_err\")\n",
    "\n",
    "    columns_spectrum_bestfit = []\n",
    "    for key in params_spectrum[0].labels:\n",
    "        columns_spectrum_bestfit.append(key)\n",
    "        columns_spectrum_bestfit.append(key + \"_err\")\n",
    "\n",
    "    # Compose dataframes\n",
    "    df1 = pd.DataFrame(columns=columns_spectrum)\n",
    "    for k, header in enumerate(headers):\n",
    "        n = int(records[k].id)\n",
    "        row = {\"id\": n}\n",
    "        for h in header:\n",
    "            if h in columns_spectrum:\n",
    "                row[h] = header[h]\n",
    "        df1.loc[len(df1)] = row\n",
    "\n",
    "    df2 = pd.DataFrame(columns=columns_spectrogram_bestfit)\n",
    "    for k, p in enumerate(params_spectrogram):\n",
    "        n = int(records[k].id)\n",
    "        row = {\"id\": n}\n",
    "        for i, key in enumerate(p.labels):\n",
    "            row[key] = p.values[i]\n",
    "            row[key + \"_err\"] = p.err[i]\n",
    "        df2.loc[len(df2)] = row\n",
    "\n",
    "    df3 = pd.DataFrame(columns=columns_spectrum_bestfit)\n",
    "    for k, p in enumerate(params_spectrum):\n",
    "        n = int(records[k].id)\n",
    "        row = {\"id\": n}\n",
    "        for i, key in enumerate(p.labels):\n",
    "            row[key] = p.values[i]\n",
    "            row[key + \"_err\"] = p.err[i]\n",
    "        df3.loc[len(df3)] = row\n",
    "\n",
    "    # Merge dataframes\n",
    "    df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "    df = pd.merge(df, df3, left_index=True, right_index=True)\n",
    "\n",
    "    df.set_index(\"DATE-OBS\", inplace=True)\n",
    "    df.index = pd.to_datetime(df.index, format=\"ISO8601\")\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    rec = df.to_records()\n",
    "    logging.info(\"Final record shape: %s\", rec.shape)\n",
    "    if not dry_run:\n",
    "        logging.info(\"Saving results to %s\", file_save)\n",
    "        np.save(file_save, rec, allow_pickle=True)\n",
    "    else:\n",
    "        logging.info(\"Dry-run: skipping file save for %s\", file_save)\n",
    "    return rec, df\n",
    "\n",
    "\n",
    "def plot_summary(rec, df, outdir=\"plots\", prefix=\"auxtel_summary\"):\n",
    "    \"\"\"\n",
    "    Save some summary plots as PNG in a directory (no GUI).\n",
    "    \"\"\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # columns to plot similar to the notebook\n",
    "    columns_to_plot = [\"D2CCD\", \"PIXSHIFT\", \"PSF_REG\", \"CHI2_FIT\", \"OUTPRESS\", \"OUTTEMP\", \"alpha_0_2\", \"TARGETX\", \"TARGETY\"]\n",
    "    for col in columns_to_plot:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        if len(col.split(\"_\")) > 1:\n",
    "            col_err = \"_\".join(col.split(\"_\")[:-1]) + \"_err_\" + col.split(\"_\")[-1]\n",
    "        else:\n",
    "            col_err = col + \"_err\"\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        if col_err in df.columns:\n",
    "            plt.errorbar(rec[\"DATE-OBS\"], rec[col], yerr=rec[col_err], linestyle=\"none\", marker=\"+\")\n",
    "        else:\n",
    "            plt.plot(rec[\"DATE-OBS\"], rec[col], linestyle=\"none\", marker=\"+\")\n",
    "\n",
    "        plt.ylim((0.9 * np.nanmin(rec[col]), 1.1 * np.nanmax(rec[col])))\n",
    "        if \"PSF_REG\" in col:\n",
    "            plt.yscale(\"log\")\n",
    "        plt.grid()\n",
    "        plt.title(col)\n",
    "        plt.gcf().autofmt_xdate()\n",
    "\n",
    "        outpng = os.path.join(outdir, f\"{prefix}_{col}.png\")\n",
    "        plt.savefig(outpng, dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point.\"\"\"\n",
    "    args = parse_args()\n",
    "    configure_logging(args.verbose)\n",
    "\n",
    "    # If local parameters define repo/collection/others, prefer them unless CLI overrides are present\n",
    "    repo = args.repo\n",
    "    if repo is None and 'FLAG_REPO_EMBARGO' in globals() and FLAG_REPO_EMBARGO:\n",
    "        repo = \"/repo/embargo\"\n",
    "    if repo is None:\n",
    "        repo = \"/repo/main\"\n",
    "\n",
    "    butler = initialize_butler(repo, embargo=args.embargo)\n",
    "    my_collection = get_collection_from_parameters(version_run_arg=args.version_run, collection_arg=args.collection)\n",
    "\n",
    "    _, records, refs = query_dataset_and_records(butler, my_collection, instrument=args.filter_instrument)\n",
    "\n",
    "    if args.only_check:\n",
    "        print(f\"Number of records: {len(records)}. Exiting by --only-check.\")\n",
    "        return\n",
    "\n",
    "    # Using a results filename default similar to the notebook naming\n",
    "    out_file = args.out_file\n",
    "    if out_file is None:\n",
    "        # fallback composition if not provided\n",
    "        collection_name = my_collection.replace(\"/\", \"_\")\n",
    "        out_file = f\"auxtel_run_{collection_name}_v1.npy\"\n",
    "\n",
    "    # Extract with multiple workers\n",
    "    logging.info(\"Starting extraction for collection %s with %d workers\", my_collection, args.n_workers)\n",
    "    results = pool_extract(refs, butler, my_collection, n_workers=args.n_workers)\n",
    "\n",
    "    # Build and save the final rec / dataframe\n",
    "    rec, df = concatenate_results_and_save(results, records, out_file, dry_run=args.dry_run)\n",
    "\n",
    "    if args.plot:\n",
    "        plot_dir = args.plot_dir\n",
    "        plot_summary(rec, df, outdir=plot_dir)\n",
    "        logging.info(\"Plots saved to %s\", plot_dir)\n",
    "\n",
    "    logging.info(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7f0e4e-37d4-473e-b15f-8c61f8e061d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from astropy.io import fits\n",
    "import getCalspec\n",
    "\n",
    "%matplotlib widget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4975b5-966e-45d4-8624-66172e2c776c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.summit.utils.utils import checkStackSetup\n",
    "checkStackSetup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957990b-82ba-4e34-bae8-20c3b0589645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK THE CONFIG HERE\n",
    "from BUTLER00_parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd041544-a4d9-4b81-bc9a-39951ce087b1",
   "metadata": {},
   "source": [
    "## Butler configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40f8dd-7abf-4b9e-81a0-5ad244af4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_NEWNAMING = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c818b0d-652d-4384-9d3e-ee06e6dca09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DumpConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dfcc69-f7b0-49b3-8131-0df1c5ca7120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lsst.daf.butler as dafButler\n",
    "\n",
    "\n",
    "if FLAG_REPO_EMBARGO:\n",
    "    repo=\"/repo/embargo\"\n",
    "else:\n",
    "    repo=\"/repo/main\"\n",
    "    \n",
    "reponame = repo.replace(\"/\",\"_\")\n",
    "\n",
    "butler = dafButler.Butler(repo)\n",
    "registry = butler.registry\n",
    "\n",
    "collection_validation = butlerusercollectiondict[version_run]\n",
    "collection_name = collection_validation.replace(\"/\",\"_\")\n",
    "output_filename = \"auxtel_run_\" + collection_name + \"_v1.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b9d75-53b8-485f-8a71-ce0f64d3f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"************************************************************************\")\n",
    "print(f\"version_run = {version_run}\")\n",
    "print(f\"repo = {repo}\")\n",
    "print(f\"collection_validation = {collection_validation}\")\n",
    "print(f\"collection_name = {collection_name}\")\n",
    "print(f\"output_filename = {output_filename}\")\n",
    "print(\"************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a4d68-b824-4396-acc7-c36c359ecc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in sorted(registry.queryCollections()):\n",
    "    if \"dagoret\" in c and \"202512\" in c:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66069d21-6177-406b-83c7-f8603a636f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#u/dagoret/auxtel_run_20251023_w_2025_42_spectractorv32_all_main_2025data_ptc_holoallfilt_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee31af-787e-462a-83f3-d6c060d18421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dt in sorted(butler.registry.queryDatasetTypes()):\n",
    "#      print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f16789-3435-4ac5-a9e5-401459f3744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat ~/rubin-user/holo_atmo_2025-09-12/bps_auxtel_atmosphere.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5495a62-be5f-4a40-9221-4dd416756406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find collection in Butler /repo/embargo\n",
    "#my_collection = ['u/dagoret/auxtel_run_20250625a']\n",
    "#my_collection = ['u/dagoret/auxtel_run_20250702b']\n",
    "#my_collection = ['u/dagoret/auxtel_run_20250912a']\n",
    "#my_collection = ['u/dagoret/auxtel_run_20250917_w_2025_25_spectractorv31_holoallfilt_a']\n",
    "my_collection = collection_validation\n",
    "# save extraction\n",
    "#file_save = \"auxtel_atmosphere_20250625a_v1.npy\"\n",
    "#file_save = \"auxtel_atmosphere_20250702b_repomain_v1.npy\"\n",
    "#file_save = \"auxtel_atmosphere_20250912a_repomain_v1.npy\"\n",
    "#file_save = \"auxtel_run_20250917_w_2025_25_spectractorv31_holoallfilt_a_repomain_v1.npy\"\n",
    "file_save = output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27531e09-1499-4049-870f-cbd3a2063d51",
   "metadata": {},
   "source": [
    "## Check the presence of the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40579354-fa78-4628-b817-32d171fe5a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetRefs = registry.queryDatasets(datasetType='spectractorSpectrum', collections=my_collection, where= \"instrument='LATISS'\")\n",
    "where = \"instrument='LATISS'\" \n",
    "records = list(butler.registry.queryDimensionRecords('visit', datasets='spectractorSpectrum', where=where,  collections=my_collection))\n",
    "refs = list(set(butler.registry.queryDatasets('spectractorSpectrum',  where=where,  collections=my_collection)))\n",
    "print(\"number of records  : \", len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825f46a-2c9b-414b-b4a3-7c2e3699adc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, r in enumerate(records):\n",
    "\n",
    "    print(f\"============= ({i}) ============datasetType = spectraction ============================================\")\n",
    "    print(\"fullId..................:\",r.id)\n",
    "    print(\"seq_num..................:\",r.seq_num)\n",
    "    print(\"day_obs..................:\",r.day_obs)\n",
    "    print(\"target..................:\",r.target_name)\n",
    "    print(\"filt+disp..................:\",r.physical_filter)\n",
    "\n",
    "    # spec = butler.get('spectractorSpectrum', visit=r.id, detector=0, collections=my_collection, instrument='LATISS')\n",
    "    \n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65440eab-5d50-44ba-95f7-62d68f10bec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete a collection\n",
    "# butler.pruneDatasets(datasetRefs, disassociate=True, unstore=True, purge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd7cc0-63df-4f9f-a1b6-e10e2baaebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "number_worker = 16\n",
    "\n",
    "\n",
    "def extract_results(\n",
    "    ref,\n",
    "    my_collection,\n",
    "):\n",
    "    nskip = 0\n",
    "    all_missing_visits = []\n",
    "    \n",
    "    try:\n",
    "        spec = butler.get(\n",
    "            \"spectractorSpectrum\",\n",
    "            visit=ref.dataId[\"visit\"],\n",
    "            collections=my_collection,\n",
    "            detector=0,\n",
    "            instrument=\"LATISS\",\n",
    "        )\n",
    "        header = spec.header\n",
    "        header[\"ID\"] = ref.dataId[\"visit\"]\n",
    "        \n",
    "        params_spectrum = butler.get(\n",
    "            \"spectrumLibradtranFitParameters\",\n",
    "            visit=ref.dataId[\"visit\"],\n",
    "            collections=my_collection,\n",
    "            detector=0,\n",
    "            instrument=\"LATISS\",\n",
    "        )\n",
    "        params_spectrogram = butler.get(\n",
    "            \"spectrogramLibradtranFitParameters\",\n",
    "            visit=ref.dataId[\"visit\"],\n",
    "            collections=my_collection,\n",
    "            detector=0,\n",
    "            instrument=\"LATISS\",\n",
    "        )\n",
    "        return header, params_spectrum, params_spectrogram\n",
    "    except:\n",
    "        nskip +=1\n",
    "        all_missing_visits.append(ref.dataId[\"visit\"])\n",
    "        if nskip%1000 == 0:\n",
    "            print(f\">>> nskip = {nskip} :: \",\"Skip\", ref.dataId[\"visit\"])\n",
    "        return None\n",
    "        \n",
    "\n",
    "if not(os.path.isfile(file_save)):\n",
    "    params_spectrum = []\n",
    "    params_spectrogram = []\n",
    "    headers = []\n",
    "\n",
    "    extract_results_function = partial(extract_results, my_collection=my_collection)\n",
    "    \n",
    "    if number_worker > 1:\n",
    "        with mp.Pool(number_worker) as pool:\n",
    "            results = list(pool.imap(extract_results_function, refs))\n",
    "    else:\n",
    "        results= []\n",
    "        for ref in refs:\n",
    "            results.append(extract_results_function(ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf67f75-5206-4653-8d97-d336d0b6c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = []\n",
    "params_spectrum = []\n",
    "params_spectrogram = []\n",
    "\n",
    "nskip = 0\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if results[i] is not None:\n",
    "        headers.append(results[i][0])\n",
    "        params_spectrum.append(results[i][1])\n",
    "        params_spectrogram.append(results[i][2])\n",
    "    else:\n",
    "        nskip +=1\n",
    "\n",
    "print(f\">>> nskip-records = {nskip} \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61972a3-74c3-4d2b-ae96-86e61c549383",
   "metadata": {},
   "source": [
    "## Load one spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40079cd-6983-4d26-b269-027e32503e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(butler.registry.getDatasetType('spectrumLibradtranFitParameters'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab71635-bc8c-4cd0-bbdf-be9a303d0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(refs_noerrorsed)):\n",
    "for i in range(20):\n",
    "    try:        \n",
    "        p = butler.get('spectrumLibradtranFitParameters', visit=refs_noerrorsed[i].dataId[\"visit\"], collections=my_collection, detector=0, instrument='LATISS')\n",
    "        err = p[\"ozone [db]\"]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74078766-d9f0-4167-b8ed-15d926a09792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(refs_noerrorsed)):\n",
    "for i in range(20):\n",
    "    try:        \n",
    "        p = butler.get('spectrogramLibradtranFitParameters', visit=refs_noerrorsed[i].dataId[\"visit\"], collections=my_collection, detector=0, instrument='LATISS')\n",
    "        err = p[\"ozone [db]\"]\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be87f8-70b2-438b-b954-4999b7274dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAG_REPO_EMBARGO:\n",
    "    dataId = {\"day_obs\": 20250107, \"seq_num\": 182, 'instrument':'LATISS',\"detector\": 0}\n",
    "else:\n",
    "    if version_run != \"run_v8\" and version_run !=\"run_v11\":\n",
    "        dataId = {\"day_obs\": 20220316, \"seq_num\": 330, 'instrument':'LATISS',\"detector\": 0}\n",
    "    else:\n",
    "        dataId = {\"day_obs\": 20250107, \"seq_num\": 182, 'instrument':'LATISS',\"detector\": 0}\n",
    "\n",
    "spec= butler.get('spectractorSpectrum',dataId,collections=my_collection)\n",
    "p = butler.get('spectrumLibradtranFitParameters',dataId,collections=my_collection)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76819dc5-5cf3-4653-bf48-90e429c1f716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "_ = spec.plot_spectrum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959b2e4-ca7c-4f99-87a4-81b83b322054",
   "metadata": {},
   "source": [
    "## Load all Libradtran parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9e7c3-9c3a-4775-a198-b6547be5e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs[0].dataId[\"visit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82dd44-9f9a-4e17-ab17-1e2422c2841b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not(os.path.isfile(file_save)):\n",
    "    # see here an efficient way to access FITS headers: https://lsstc.slack.com/archives/CBV7K0DK6/p1700250222827499\n",
    "    params_spectrum = []\n",
    "    params_spectrogram = []\n",
    "    headers = []\n",
    "    \n",
    "    def from_ref_to_dataId(ref):\n",
    "        dataId = {'day_obs': ref.dataId[\"day_obs\"], 'seq_num': int(str(ref.dataId[\"visit\"])[8:]), 'instrument': 'LATISS', 'detector': 0}\n",
    "        return dataId\n",
    "    \n",
    "    for ref in tqdm(sorted(refs, key=lambda x: x.dataId[\"visit\"])[::]):\n",
    "        try:\n",
    "            spec = butler.get('spectractorSpectrum', visit=ref.dataId[\"visit\"], collections=my_collection, detector=0, instrument='LATISS')\n",
    "            headers.append(spec.header)\n",
    "            p = butler.get('spectrumLibradtranFitParameters', visit=ref.dataId[\"visit\"], collections=my_collection, detector=0, instrument='LATISS')\n",
    "            params_spectrum.append(p)\n",
    "            p = butler.get('spectrogramLibradtranFitParameters', visit=ref.dataId[\"visit\"], collections=my_collection, detector=0, instrument='LATISS')\n",
    "            params_spectrogram.append(p)\n",
    "        except (AttributeError,ValueError,LookupError):\n",
    "            print(\"Skip\", ref.dataId[\"visit\"])\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4677f0-f79e-4dc9-b6f6-49b044d3d1b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not(os.path.isfile(file_save)):\n",
    "    columns_spectrum = [\"id\"]\n",
    "    \n",
    "    for h in headers[0]:\n",
    "        if \"COMMENT\" in h or \"EXTNAME\" in h: continue\n",
    "        if \"LBDAS_T\" in h or \"PSF_P_T\" in h or \"AMPLIS_T\" in h: continue\n",
    "        if \"UNIT\" in h: continue\n",
    "        if \"SIMPLE\" in h: continue\n",
    "        columns_spectrum.append(h)\n",
    "     \n",
    "    columns_spectrogram_bestfit = []\n",
    "    for key in params_spectrogram[0].labels:\n",
    "        columns_spectrogram_bestfit.append(key)\n",
    "        columns_spectrogram_bestfit.append(key+\"_err\")\n",
    "    \n",
    "    columns_spectrum_bestfit = []\n",
    "    for key in params_spectrum[0].labels:\n",
    "        columns_spectrum_bestfit.append(key)\n",
    "        columns_spectrum_bestfit.append(key+\"_err\")\n",
    "    \n",
    "    min_index = 0\n",
    "    max_index = np.inf\n",
    "\n",
    "    #df1 is header info\n",
    "    df1 = pd.DataFrame(columns=columns_spectrum)\n",
    "    \n",
    "    for k, header in enumerate(headers):\n",
    "        # if k > 40: break\n",
    "        n = records[k].id\n",
    "        if n < min_index or n > max_index: continue\n",
    "        row = {\"id\": n}\n",
    "        for h in header:\n",
    "            if h in columns_spectrum:\n",
    "                row[h] = header[h]\n",
    "        df1.loc[len(df1)] = row\n",
    "\n",
    "    #df2 is spectrogram     spectrogram best fit\n",
    "    df2 = pd.DataFrame(columns=columns_spectrogram_bestfit)\n",
    "    \n",
    "    for k, p in enumerate(params_spectrogram):\n",
    "        n = records[k].id\n",
    "        if n < min_index or n > max_index: continue\n",
    "        row = {\"id\": n}\n",
    "        for i, key in enumerate(p.labels):\n",
    "            row[key] = p.values[i]\n",
    "            row[key+\"_err\"] = p.err[i]\n",
    "        df2.loc[len(df2)] = row\n",
    "\n",
    "    # df3 is spectrum best fit    \n",
    "    df3 = pd.DataFrame(columns=columns_spectrum_bestfit)\n",
    "\n",
    "    \n",
    "    for k, p in enumerate(params_spectrum):\n",
    "        n = records[k].id\n",
    "        if n < min_index or n > max_index: continue\n",
    "        row = {\"id\": n}\n",
    "        for i, key in enumerate(p.labels):\n",
    "            row[key] = p.values[i]\n",
    "            row[key+\"_err\"] = p.err[i]\n",
    "        df3.loc[len(df3)] = row\n",
    "\n",
    "    # merge header with spectrogram\n",
    "\n",
    "    if FLAG_NEWNAMING:\n",
    "        df = pd.merge(df1, df2, left_index=True, right_index=True, suffixes=['','_ram'])\n",
    "        df = pd.merge(df, df3, left_index=True, right_index=True, suffixes=['','_rum'])  \n",
    "    else:\n",
    "        df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "        # merge (header-spectrogram with spectrum)\n",
    "        df = pd.merge(df, df3, left_index=True, right_index=True)\n",
    "        \n",
    "    df.set_index('DATE-OBS', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index, format=\"ISO8601\") #['DATE-OBS'])\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    rec = df.to_records()\n",
    "    np.save(file_save, rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d0eb3-ca38-4842-a97b-929dfc6e790e",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450003bc-5a85-4a4d-b2d9-06abdd5cb0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rec = np.load(file_save, allow_pickle=True)\n",
    "df = pd.DataFrame(rec)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04b901-4240-4552-8cf0-88fb909bba46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in [\"D2CCD\", \"PIXSHIFT\", \"PSF_REG\", \"CHI2_FIT\", \"OUTPRESS\", \"OUTTEMP\", \"alpha_0_2\", \"TARGETX\", \"TARGETY\"]:\n",
    "    if col not in df.columns: continue\n",
    "    if len(col.split('_')) > 1:\n",
    "        col_err = '_'.join(col.split('_')[:-1])+\"_err_\"+col.split('_')[-1]\n",
    "    else:\n",
    "        col_err = col+\"_err\"\n",
    "    fig = plt.figure()\n",
    "    if col_err in df.columns:\n",
    "        plt.errorbar(rec[\"DATE-OBS\"], rec[col], yerr=rec[col_err], linestyle=\"none\", marker=\"+\")\n",
    "    else:\n",
    "        plt.plot(rec[\"DATE-OBS\"], rec[col], linestyle=\"none\", marker=\"+\")\n",
    "    plt.ylim((0.9*np.min(rec[col]), 1.1*np.max(rec[col])))\n",
    "    if \"PSF_REG\" in col:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.grid()\n",
    "    plt.title(col)\n",
    "    plt.legend()\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879b0a3-98da-466d-8558-11a039058a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered = (rec[\"CHI2_FIT\"] < 30) & (rec[\"PSF_REG\"] > 1e-2) & (rec[\"D2CCD\"] > 186.7)  & (rec[\"D2CCD\"] < 187.4)  & (rec[\"PIXSHIFT\"] > 0.5)  & (rec[\"PIXSHIFT\"] < 1.5) \n",
    "print(len(filtered[filtered]))\n",
    "filtered = filtered & (rec[\"PWV [mm]_err_x\"] > 0) & (rec[\"PWV [mm]_err_x\"] < 5) & (rec[\"PWV [mm]_err_y\"] > 0) & (rec[\"PWV [mm]_err_y\"] < 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc5bda-456b-40e5-b78f-eada7bac41af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(filtered[filtered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347c9a9-64e6-4c3d-9099-46b54946baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = np.full(rec[\"CHI2_FIT\"].shape,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff29c78-1918-452a-a555-f722cdb08dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cea579-128b-48f9-a47a-383247c4b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"D2CCD\", \"PIXSHIFT\", \"PSF_REG\", \"CHI2_FIT\", \"OUTPRESS\", \"OUTTEMP\", \"OUTHUM\", \"alpha_0_2\", \"TARGETX\", \"TARGETY\"]:\n",
    "    if col not in df.columns: continue\n",
    "    if len(col.split('_')) > 1:\n",
    "        col_err = '_'.join(col.split('_')[:-1])+\"_err_\"+col.split('_')[-1]\n",
    "    else:\n",
    "        col_err = col+\"_err\"\n",
    "    fig = plt.figure()\n",
    "    if col_err in df.columns:\n",
    "        plt.errorbar(rec[\"DATE-OBS\"][filtered], rec[col][filtered], yerr=rec[col_err][filtered], linestyle=\"none\", marker=\"+\")\n",
    "    else:\n",
    "        plt.plot(rec[\"DATE-OBS\"][filtered], rec[col][filtered], linestyle=\"none\", marker=\"+\")\n",
    "    plt.ylim((0.9*np.nanmin(rec[col][filtered]), 1.1*np.nanmax(rec[col][filtered])))\n",
    "    if \"PSF_REG\" in col:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.grid()\n",
    "    plt.title(col)\n",
    "    plt.legend()\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe87397-9b18-4393-82f8-7c4dc757ab27",
   "metadata": {},
   "source": [
    "### Spectrum fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69afbf44-a613-47d3-81af-1848c8e7a997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in [\"A1_y\", \"chi2_y\", \"ozone [db]_y\", \"PWV [mm]_y\", \"VAOD_y\", \"A2_y\", \"D_CCD [mm]_y\", \"alpha_pix [pix]\", \"reso [nm]\", \"B_y\"]:\n",
    "    if col not in df.columns: \n",
    "        continue\n",
    "    if len(col.split('_')) > 1:\n",
    "        col_err = '_'.join(col.split('_')[:-1])+\"_err_\"+col.split('_')[-1]\n",
    "    else:\n",
    "        col_err = col+\"_err\"\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    if col_err in df.columns:\n",
    "        plt.errorbar(rec[\"DATE-OBS\"][filtered], rec[col][filtered], yerr=rec[col_err][filtered], linestyle=\"none\", marker=\"+\")\n",
    "    else:\n",
    "        plt.plot(rec[\"DATE-OBS\"][filtered], rec[col][filtered], linestyle=\"none\", marker=\"+\")\n",
    "    #plt.ylim((0.9*np.min(rec[col][filtered]), 1.1*np.max(rec[col][filtered])))\n",
    "    plt.grid()\n",
    "    plt.title(col)\n",
    "    plt.legend()\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae610c5-ebd4-41a5-ba55-ab95580226c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filters = np.unique(rec[\"FILTER\"])\n",
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27410b11-f923-46a9-974b-39e68690cc0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in [\"A1_y\", \"chi2_y\", \"ozone [db]_y\", \"PWV [mm]_y\", \"VAOD_y\", \"A1_y\", \"A2_y\", \"D_CCD [mm]_y\", \"alpha_pix [pix]\", \"reso [nm]\", \"B_y\"]:\n",
    "    if col not in df.columns: \n",
    "        continue\n",
    "    if len(col.split('_')) > 1:\n",
    "        col_err = '_'.join(col.split('_')[:-1])+\"_err_\"+col.split('_')[-1]\n",
    "    else:\n",
    "        col_err = col+\"_err\"\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    for filt in filters:\n",
    "        if filt in [\"HD60753\", \"HD37962\"]:\n",
    "            continue\n",
    "        index = filtered & (rec[\"FILTER\"] == filt)\n",
    "        if col_err in df.columns:\n",
    "            plt.errorbar(rec[\"DATE-OBS\"][index], rec[col][index], yerr=rec[col_err][index], linestyle=\"none\", marker=\"+\", label=filt)\n",
    "        else:\n",
    "            plt.plot(rec[\"DATE-OBS\"][index], rec[col][index], linestyle=\"none\", marker=\"+\")\n",
    "    plt.ylim((0.9*np.min(rec[col][filtered]), 1.1*np.max(rec[col][filtered])))\n",
    "    plt.grid()\n",
    "    plt.title(col)\n",
    "    plt.legend()\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7465b5-4713-4ca4-8aed-3316f57210a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stars = np.unique(rec[\"TARGET\"])\n",
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5cadc8-fe8f-407c-8494-a7276d245756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in [\"A1_y\", \"chi2_y\", \"ozone [db]_y\", \"PWV [mm]_y\", \"VAOD_y\", \"angstrom_exp_y\", \"A2_y\", \"D_CCD [mm]_y\", \"alpha_pix [pix]\", \"reso [nm]\", \"B_y\", \"alpha_0_2\", \"alpha_0_1\", \"gamma_0_2\", \"gamma_0_1\", \"y_c_0_2\", \"y_c_0_1\"]:\n",
    "    if col not in df.columns: \n",
    "        continue\n",
    "    if len(col.split('_')) > 1:\n",
    "        col_err = '_'.join(col.split('_')[:-1])+\"_err_\"+col.split('_')[-1]\n",
    "    else:\n",
    "        col_err = col+\"_err\"\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    for star in stars:\n",
    "        #if star not in [\"HD185975\"]:\n",
    "        #    continue\n",
    "        index = filtered & (rec[\"TARGET\"] == star)\n",
    "        if col_err in df.columns and False:\n",
    "            plt.errorbar(rec[\"DATE-OBS\"][index], rec[col][index], yerr=rec[col_err][index], linestyle=\"none\", marker=\"+\", label=star)\n",
    "        else:\n",
    "            plt.plot(rec[\"DATE-OBS\"][index], rec[col][index], linestyle=\"none\", marker=\"+\")\n",
    "    plt.ylim((0.9*np.nanmin(rec[col][filtered]), 1.1*np.nanmax(rec[col][filtered])))\n",
    "    plt.grid()\n",
    "    plt.title(col)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig.autofmt_xdate()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6d8bb-ab0b-4254-a229-67393ab4d97f",
   "metadata": {},
   "source": [
    "### Spectrogram forward model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d17fb-78c6-49a6-a0aa-196ca554a10c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filters = np.unique(rec[\"FILTER\"])\n",
    "filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c3be9-8e29-4101-ab63-8cb5e0ad091e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in [\"A1_x\", \"ozone [db]_x\", \"PWV [mm]_x\", \"VAOD_x\", \"D_CCD [mm]_x\"]: #, \"gamma_0\", \"alpha_0\"]:\n",
    "    if len(col.split('_')) > 1:\n",
    "        col_err = '_'.join(col.split('_')[:-1])+\"_err_\"+col.split('_')[-1]\n",
    "    else:\n",
    "        col_err = col+\"_err\"\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    for filt in filters:\n",
    "        index = filtered & (rec[\"FILTER\"] == filt)\n",
    "        if col_err in df.columns:\n",
    "            plt.errorbar(rec[\"DATE-OBS\"][index], rec[col][index], yerr=rec[col_err][index], linestyle=\"none\", marker=\"+\")\n",
    "        else:\n",
    "            plt.plot(rec[\"DATE-OBS\"][index], rec[col][index], linestyle=\"none\", marker=\"+\")\n",
    "    plt.ylim((0.9*np.min(rec[col][filtered]), 1.1*np.max(rec[col][filtered])))\n",
    "    plt.grid()\n",
    "    plt.title(col)\n",
    "    plt.legend()\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e754c-c13c-4f34-aa0b-2031c7ac45d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stars = np.unique(rec[\"TARGET\"])\n",
    "#stars = ['HD2811', 'HD38666']  # , 'HD185975'\n",
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715bc47b-f0ff-4c08-89b2-7f867b9efde9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in [\"A1_x\", \"ozone [db]_x\", \"PWV [mm]_x\", \"VAOD_x\", \"angstrom_exp_x\", \"D_CCD [mm]_x\", \"gamma_0_2\", \"alpha_0_2\"]:\n",
    "    if len(col.split('_')) > 1:\n",
    "        col_err = '_'.join(col.split('_')[:-1])+\"_err_\"+col.split('_')[-1]\n",
    "    else:\n",
    "        col_err = col+\"_err\"\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    for star in stars : #['HD185975']: #stars:\n",
    "        index = filtered & (rec[\"TARGET\"] == star)\n",
    "        if not getCalspec.is_calspec(star):\n",
    "            marker = \"o\"\n",
    "        else:\n",
    "            marker = \"+\"\n",
    "        if col_err in df.columns:\n",
    "            plt.errorbar(rec[\"DATE-OBS\"][index], rec[col][index], yerr=rec[col_err][index], linestyle=\"none\", marker=marker, label=star)\n",
    "        else:\n",
    "            plt.plot(rec[\"DATE-OBS\"][index], rec[col][index], linestyle=\"none\", marker=marker)\n",
    "    plt.ylim((0.9*np.min(rec[col][filtered]), 1.1*np.max(rec[col][filtered])))\n",
    "    plt.grid()\n",
    "    plt.title(col)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig.autofmt_xdate()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62459cb-b79a-4331-bfa7-77786e04a5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
